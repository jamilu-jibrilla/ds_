{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!source venv/bin/activate  # Windows: venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Flask tensorflow opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Admin/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Height: 1, Input Width: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "input_height, input_width = model.classifier[0].convs[0][0].weight.shape[2:]\n",
    "print(f\"Input Height: {input_height}, Input Width: {input_width}\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Resize to model's input size\n",
    "    image = cv2.resize(image, (input_height, input_width))\n",
    "    # Normalize pixel values (typical range: 0-1 or -1 to 1)\n",
    "    image = image / 255.0\n",
    "     # Convert toCHW format (channels first) expected by PyTorch models\n",
    "    image = image.transpose((2, 0, 1))  \n",
    "    # Convert NumPy array to PyTorch tensor\n",
    "    image = torch.from_numpy(image).float()\n",
    "\n",
    "    # Expand dimensions for batch processing (if needed)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "image_path = r'C:\\Users\\Admin\\Desktop\\ds_internship\\day_8\\home.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "check = preprocess_image(image)\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(image_path)\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)['out'][0]\n",
    "output_predictions = output.argmax(0)\n",
    "\n",
    "\n",
    "print(output_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c7c12b10a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "# plot the semantic segmentation predictions of 21 classes in each color\n",
    "r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_image.size)\n",
    "r.putpalette(colors)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(r)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
